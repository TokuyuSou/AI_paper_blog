{
  "title": "Paper Explained: Tongyi DeepResearch Technical Report - A Beginner's Guide",
  "subtitle": "AI That Drives Its Own Deep Research",
  "category": "Foundation Models",
  "authors": [
    "Tongyi DeepResearch Team",
    "Baixuan Li",
    "Bo Zhang",
    "Dingchu Zhang",
    "Fei Huang",
    "Guangyu Li",
    "Guoxin Chen",
    "Huifeng Yin",
    "Jialong Wu",
    "Jingren Zhou",
    "Kuan Li",
    "Liangcai Su",
    "Litu Ou",
    "Liwen Zhang",
    "Pengjun Xie",
    "Rui Ye",
    "Wenbiao Yin",
    "Xinmiao Yu",
    "Xinyu Wang",
    "Xixi Wu",
    "Xuanzhong Chen",
    "Yida Zhao",
    "Zhen Zhang",
    "Zhengwei Tao",
    "Zhongwang Zhang",
    "Zile Qiao",
    "Chenxi Wang",
    "Donglei Yu",
    "Gang Fu",
    "Haiyang Shen",
    "Jiayin Yang",
    "Jun Lin",
    "Junkai Zhang",
    "Kui Zeng",
    "Li Yang",
    "Hailong Yin",
    "Maojia Song",
    "Ming Yan",
    "Peng Xia",
    "Qian Xiao",
    "Rui Min",
    "Ruixue Ding",
    "Runnan Fang",
    "Shaowei Chen",
    "Shen Huang",
    "Shihang Wang",
    "Shihao Cai",
    "Weizhou Shen",
    "Xiaobin Wang",
    "Xin Guan",
    "Xinyu Geng",
    "Yingcheng Shi",
    "Yuning Wu",
    "Zhuo Chen",
    "Zijian Li",
    "Yong Jiang"
  ],
  "paper_url": "https://arxiv.org/abs/2510.24701v1",
  "read_time": "10 min read",
  "publish_date": "2025-10-29",
  "concept_explained": "Mixture of Experts",
  "content": {
    "background": "Before this work, large language models were really good at quick Q&A, short tasks, or simple summaries. But real deep research is different: it’s a long, multi-step journey. A researcher might plan what to look for, search many sources, read and compare them, keep track of what’s true and what isn’t, and then weave together a careful, well-supported picture. Traditional models often lose track of the bigger goal, get stuck in one thread, or start repeating or making up facts. Building systems to do this kind of sustained, reliable investigation also tends to require a lot of hand-labeled training data from experts, which is expensive and slow.\n\nThere’s a growing need for AI that can act more like a research partner—able to autonomously pursue a topic over many steps, across vast information sources, and produce coherent, evidence-based insights. In university and industry settings, people want tools that can conduct long, careful investigations (think literature reviews or multi-source analyses) with less bottleneck from human annotation. To teach such behavior at scale, we also need training pipelines and environments that can automatically generate practice tasks and safely refine the model’s reasoning across many rounds, rather than relying on small, manually labeled datasets.\n\nSo the motivation behind Tongyi DeepResearch is to address these gaps: to push AI toward truly long-horizon, autonomous information gathering and synthesis, backed by scalable, automatic training and evaluation methods, and to share these advances openly so a broad community can build better, more trustworthy research aids for students and professionals alike.",
    "methodology": "Tongyi DeepResearch is an “agentic” large language model designed to act like a proactive researcher. Think of it as a graduate student who can plan a long project, search for sources, summarize what it finds, check if its ideas make sense, and decide what to do next without being told every step. Its core goal is to handle long-horizon research tasks—where you need to reason over many moves, gather information from different places, and adjust your plan as you go.\n\nHere’s how they approached this, in simple terms, and why it’s innovative:\n\n- Two-stage agentic training: They teach the model to be an autonomous researcher in two big steps—agentic mid-training and agentic post-training. The mid-training phase helps the model develop planning and information-seeking skills, while the post-training phase refines how it acts as an agent (how it decides what to do next). Imagine first learning how to outline a project and formulate questions, then later learning how to execute tasks smoothly and troubleshoot when things don’t go as planned.\n\n- Fully automatic data generation and environments: Instead of relying on humans to label or craft teaching data, they built a scalable, automatic data-synthesis pipeline. It creates lots of simulated research tasks, prompts, feedback signals, and interaction scenarios. Each stage gets its own customized environment to keep the training interactions stable and consistent—like giving the student a carefully designed lab, library, and notebook environment tuned for different kinds of tasks to reduce chaos and confusion during learning.\n\n- Efficient, large-scale model with sparse activation: The model has a large overall size (30.5 billion parameters) but uses a sparse activation approach, meaning only a portion of the parameters respond for a given token. This is like having a big team where only the most relevant members contribute to a particular problem, making the system more efficient without sacrificing capability.\n\nWhat this achieves and why it matters:\n\n- It reaches state-of-the-art performance on several agentic deep-research benchmarks (examples include Humanity’s Last Exam, BrowseComp, BrowseComp-ZH, WebWalkerQA, xbench-DeepSearch, FRAMES, and xbench-DeepSearch-2510). In other words, the approach scales to complex, multi-step information-seeking tasks and can outperform prior methods on those kinds of challenges.\n\n- The work is open-source: the model, the training framework, and complete solutions are released to the community, so researchers and students can study, reuse, and build on it.\n\nIn short, Tongyi DeepResearch combines a thoughtfully staged training process, a fully automated way to generate diverse training experiences, and a scalable, efficient model design to push AI toward truly autonomous, long-range research tasks.",
    "results": "Tongyi DeepResearch is like a research-minded AI assistant designed to handle long, complex projects. It’s built as an agentic large language model, meaning it can plan ahead, decide what to do next, and carry out a sequence of research actions (instead of just answering a single question). The team trained it in an end-to-end way that blends two kinds of agent-like training: the model learns to plan and act during the training itself (mid-training) and then refines its behavior after training (post-training). A key idea is to teach the model to do deep information gathering and reasoning across many steps, so it can tackle big questions and synthesize findings over time.\n\nOne major leap here is the way they generate training data automatically, without heavy human annotation. They built a fully automatic data-synthesis pipeline that creates the kinds of tasks the model will face, and they design customized, staged environments to keep interactions stable as the model learns. Because of this, Tongyi DeepResearch can improve its planning, searching, and cross-source reasoning more efficiently than prior systems. In tests, it reached the top performance on several challenging benchmarks designed to measure agent-like deep research skills, such as long-form information seeking and multi-step reasoning tasks. This combination of end-to-end agentic training, scalable data generation, and tailored training environments is where the real breakthroughs lie.\n\nIn practical terms, the work has meaningful impact for university researchers, students, and professionals who need to survey literature, compare sources, and build well-supported conclusions. It promises to speed up literature reviews, help with complex project planning, and produce coherent, cross-referenced summaries from many sources. Because the model, framework, and solutions are open-source, others can reproduce, critique, and improve the system, accelerating the development of autonomous research tools in the community. Overall, Tongyi DeepResearch demonstrates a viable path toward AI that can autonomously manage long, multi-step research tasks—potentially changing how we approach deep information gathering and decision-making.",
    "significance": "Tongyi DeepResearch matters today because it moves AI from answering single questions to running long, multi-step research projects on its own. The paper describes an agentic large language model trained end-to-end for deep information-seeking tasks, combining mid-training and post-training to build scalable reasoning and browsing capabilities. It also uses a fully automatic data-synthesis pipeline (no costly human annotation) and custom environments that keep interactions stable as the agent works through long horizons. The result is a model with 30.5 billion parameters but only about 11% of them are active per token, which points to a sparse, more cost-efficient way to run large reasoning systems. This combination—autonomous planning, long-term information gathering, and scalable data creation—addresses a core bottleneck in AI right now: how to empower machines to carry out sustained, credible research of-the-pressing complexity.\n\nIn the long run, Tongyi DeepResearch helps shape how we design and deploy future AI systems that can think, plan, and learn across many steps and sources. Its emphasis on agentic training and customizable environments lays a blueprint for safer, more capable autonomous researchers that can be audited and improved over time. By open-sourcing the model, framework, and end-to-end solutions, the authors invite the community to reproduce results, critique methods, and build upon the platform—accelerating progress and better aligning tools with real-world research workflows. The approach also highlights a shift toward sparse, scalable computation in large models, which is a practical path to bigger, smarter agents without prohibitive cost.\n\nThis work already echoes in modern AI systems you may have seen: ChatGPT and other chat-based assistants are now layered with browsing, memory, and tool-use capabilities, but Tongyi DeepResearch pushes that idea toward true long-horizon autonomy. It informs autonomous research copilots, literature-review tools, and web-browsing agents that can plan a multi-step investigation, gather sources, compare evidence, and produce integrated results. Because the project targets real research tasks and provides benchmarks like Humanity’s Last Exam, BrowseComp, WebWalkerQA, and others, it gives we students and developers concrete tests to measure and improve long-term reasoning and information-seeking abilities. In short, this paper matters now because it points to a future where AI can autonomously conduct meaningful, credible research over days or weeks, reshaping how we learn, innovate, and validate new ideas."
  },
  "concept_explanation": {
    "title": "Understanding Mixture of Experts: The Heart of Tongyi DeepResearch Technical Report",
    "content": "Imagine you’re running a big company with lots of specialists: a librarian for legal questions, a scientist for experiments, a math whiz, a literature reviewer, and a project planner. Instead of paying everyone all the time, you have a smart boss (the gate) who looks at your question and picks just the right subset of specialists to handle it. After they work, their answers are combined into one final response. This setup is a good real-world analogy for Mixture of Experts (MoE) in AI. In MoE, the model is built from many “experts” (neural networks specialized in different kinds of reasoning), but for any single input, only a small group of these experts actually get to work. This keeps the compute manageable while letting the model grow very large and capable.\n\nHere’s how MoE works, step by step, in simple terms. First, an input text arrives. A gating network looks at the input and decides which experts should handle it, often picking a small number (like the top-2 or top-4) based on what the input needs. Next, the chosen experts each process the input, generating their own pieces of the answer. Those pieces are then weighted and combined to produce the model’s final next-token prediction or decision. During training, the system also tries to keep the load balanced so no single expert gets overwhelmed, and it learns to assign inputs to the most helpful specialists. In many systems, only a fraction of all experts are active for any given token, which is why you hear about “sparse” activation in MoE.\n\nIn the Tongyi DeepResearch paper, the model is described as a very large agentic LLM with 30.5 billion parameters, but with only about a tenth of those parameters active per token (roughly 3.3 billion) during processing. That pattern matches a sparse Mixture of Experts design: the model can have many more parameters overall, but for each moment of use, only a small subset is actually used. This allows Tongyi to keep per-token compute relatively efficient while still giving the system a huge pool of specialized capabilities. The specialization can be organized around different kinds of research tasks—like one expert for deep literature search, another for data extraction, another for logical reasoning, and another for planning long-term steps.\n\nWhy is this important for long-horizon, deep research tasks like those Tongyi aims to tackle? Because long research sessions often require multiple kinds of thinking in sequence: locating sources, summarizing findings, comparing conflicting results, planning next steps, and building a coherent synthesis. With MoE, the model can route different parts of the problem to the most suitable experts who are tuned for those sub-tasks. For example, one expert might be a “literature navigator” that spots key papers and extracts relevant quotes; another is a “reasoning organizer” that builds a step-by-step plan; another is a “summarizer” that writes clear, concise takeaways. By combining these specialized minds, the system can reason more effectively over long interactions and keep the process scalable as the model grows.\n\nPractically, this architecture enables powerful, scalable AI assistants for research and information gathering. In real-world use, you could deploy a Tongyi-like system to conduct comprehensive literature reviews, monitor evolving research topics, synthesize evidence from many sources, design experiments, or draft policy-relevant reports—all while keeping inference costs reasonable thanks to sparse activation. Beyond academia, MoE-based designs are also useful in fields like software engineering, data science, and policy analysis—anywhere you need a big, versatile model that can switch between different kinds of thinking without blazing through all its parameters for every query. Open-source releases and end-to-end training ideas, like those in Tongyi DeepResearch, help the community study these ideas, test them on real tasks, and build practical tools for researchers and decision-makers."
  },
  "summary": "This paper introduces Tongyi DeepResearch, an autonomous, goal-driven language model designed for long-horizon research tasks, built with an end-to-end training framework and a fully automatic data-synthesis pipeline to enable scalable reasoning, achieving state-of-the-art results on deep-research benchmarks and releasing the model and framework as open source.",
  "paper_id": "2510.24701v1",
  "arxiv_url": "https://arxiv.org/abs/2510.24701v1",
  "categories": [
    "cs.CL",
    "cs.AI",
    "cs.IR",
    "cs.LG",
    "cs.MA"
  ]
}